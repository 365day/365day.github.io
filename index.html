
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Alfred's Blog</title>
  <meta name="author" content="GaoChuanjun">

  
  <meta name="description" content="一、网站类产品常用指标 页面浏览量（Page View，PV）：在一定统计周期内（通常为24小时）所有访问者浏览的页面总数。该指标重复计算，即如果一个访问者浏览同一页面3次，那么PV就计算为3个。PV之于网站，就像是收视率之于电视，从某种意义上已成为投资者衡量商业网站表现的最重要尺度之一。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://365day.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Alfred's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Alfred's Blog</a></h1>
  
    <h2>博客，不仅仅是分享，也是一个自我学习的过程——alfred.2014/05/07</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:365day.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/26/zeng-chang-hei-ke-ying-dang-guan-zhu-de-chang-yong-zhi-biao/">增长黑客应当关注的常用指标</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-26T16:09:42+08:00" pubdate data-updated="true">Mar 26<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h4>一、网站类产品常用指标</h4>

<ul>
<li>页面浏览量（Page View，PV）：在一定统计周期内（通常为24小时）所有访问者浏览的页面总数。该指标重复计算，即如果一个访问者浏览同一页面3次，那么PV就计算为3个。PV之于网站，就像是收视率之于电视，从某种意义上已成为投资者衡量商业网站表现的最重要尺度之一。严格意义上来说，PV只记录了页面被加载显示出的次数，并不能真正确保用户进行了浏览，有些网站会利用这一特性“刷”PV，例如在页面中嵌入不可见的iframe。还有的网站编辑为了完成PV指标，会将一篇长文（或组图）拆分成多页，从而制造出阅读量大的假象。</li>
<li>独立访问者（Unique Visitor，UV）：在一定统计周期内访问某站点的不同IP地址的人数。通常在同一天内，UV只记录第一次进入网站的具有独立IP的访问者。如果某人访问<a href="http://www.fengqu.com/">丰趣海淘首页</a>，又点开了三条商品详情，则记作4个PV和1个UV。UV反应了网站覆盖的绝对人数，但没有体现出访问者在网站上的全面活动。此外，由于校园网络、企业机关等一些部门通常有统一的对外IP出口，依靠IP来判断的UV也并不能做到完全准确，更优的做法是结合Cookies。</li>
<li>访问数（Visit）：访问者从进入网站到离开网站之间的整个交互过程，视作一次Visit。它可能包含一组页面浏览行为。通常界定同一访问者的两次不同Visit的判定方式是间隔时长，如30分钟。这意味着如果同一访问者连续两次页面访问之间间隔为15分钟，则视作一次Visit；如果间隔41分钟（因故暂时离开或阅读了一篇长文），则被切分为两次Visit。</li>
<li>着陆页（Landing Page）：指访问者浏览网站时所到达的第一个页面，又称用户捕获页。针对着陆页的分析追踪可作为判定外部广告或其他营销推广活动效果的依据，因此着陆页应当是经过恰当优化的。</li>
<li>退出页（Exit Page）：指访问者浏览网站时所访问的最户一个页面。退出页数量大，并不等于网站的黏性差，此时应当参照退出数与页面浏览量的比值，即退出率。若某个页面本不该有较高的退出率（如在线购买流程的下单环节），则需要检查该页面，防止其成为整站的流量漏洞。</li>
<li>跳出率（Bounce Rate）：用户衡量整站或网页的黏性。跳出，指访问者仅仅浏览了一个网页就结束了访问（Visit）。整站跳出率 = 全站跳出数 / 全站页面浏览量，它反映了整站的导航效率；而针对单独页面计算的跳出率 = 该页面跳出数 / 该页面浏览量，它是对单个网页导航能力的评价。一般而言，跳出率越高代表网站的问题越大。</li>
<li>展现数（Impressions）：又称印象数，指广告在浏览器中被加载的次数。只要广告内容被加载出一次（如刷新了页面），展现数就加1。</li>
<li>服务器打点数（Hit）：打点指服务器收到一次请求。如访问者浏览了一个仅有10张图片的网页，则打点数记作11，其中包括1次网页请求和10次加载图片的请求。</li>
<li>转化率（Conversion Rate）：转化，指达成了某种预设的目标，如引导用户完成下载、注册、新闻订阅、走完新手介绍流程等。转化率是计量这种转化成效的指标，可用于衡量网站内容对访问者的吸引程度和宣传效果等。例如，广告条的转化率 = 通过广告条点击进入着陆页的流量 / 广告条的展现数；注册的转化率 = 完成注册流量的用户数 /到达注册页面的流量。</li>
<li>停留时间（Duration）：指一次访问的持续时长。通常较为简单的计算方法是用最后一次访问的时间减去访问第一张页面的时间（但这将无法统计最后一次访问的持续时长）。</li>
<li>初访者（New Visitor）：初次访问网站的访问者。通常用Cookie判断，并以一定时限为统计周期，通常为一个月。如果上月某人访问过网站，次月再次访问，则对于次月内的第一次访问行为而言，这个访问者扔视作该月内的一个新的初访者。</li>
<li>回访者（Return Visitor）：相对初访者而言，如果一个访问者在该月内重复访问，则视作回访者，也就是“回头客”。该指标衡量网站内容对访问者的吸引程度和网站实用性。统计周期内所有初访者数量 + 所有回访者数量 = 独立访问者数量。</li>
<li>访问来源（Referrer）：指一次访问或一个网页浏览的流量来源，又被称作“推荐来源”。访问来源可从不同维度进行划分。如按来源网站的性质，可划分为来自搜索引擎、网站推荐（如友情链接、广告条、软文植入）、无网站来源（用户直接进入网站，如从浏览器收藏夹点入、直接在地址栏输入域名等）；按来源网址的形式，可划分为来自域（如fanbing.net）、网站（如www.fanbing.net）或URL（如<a href="http://www.fanbing.net/about.html%EF%BC%89%EF%BC%9B%E6%8C%89%E7%85%A7%E5%86%85%E5%A4%96%E9%83%A8%EF%BC%8C%E5%8F%AF%E5%88%92%E5%88%86%E4%B8%BA%E7%AB%99%E5%A4%96%E9%93%BE%E6%8E%A5%E6%88%96%E7%AB%99%E5%86%85%E6%9D%A5%E6%BA%90%E3%80%82">http://www.fanbing.net/about.html%EF%BC%89%EF%BC%9B%E6%8C%89%E7%85%A7%E5%86%85%E5%A4%96%E9%83%A8%EF%BC%8C%E5%8F%AF%E5%88%92%E5%88%86%E4%B8%BA%E7%AB%99%E5%A4%96%E9%93%BE%E6%8E%A5%E6%88%96%E7%AB%99%E5%86%85%E6%9D%A5%E6%BA%90%E3%80%82</a></li>
<li>其他属性：有的第三方统计工具可结合自身收集的其他数据，获取访问者的进一步的信息，如地域分布、系统环境、性别比例、年龄分布、学历分布、职业分布等。</li>
</ul>


<h4>二、软件及移动应用类产品常用指标</h4>

<ul>
<li>新增用户数（New Users）：值首次打开应用的用户数量，通常通过设备识别符（如苹果系统的UDID）来识别用户的唯一身份。由于传输统计数据需要联网，因此即便是首次打开应用，若未能联网，也统计不到。此外，卸载再安装通常不会算作新增用户，老用户的版本升级也不会计算在内。当然，如果下载了应用但并未安装，或安装之后没有启动过，也无法统计为新增用户。</li>
<li>活跃用户数（Active Users）：指统计周期内有过特定使用行为的用户数量。同一用户在一个统计周期内多次使用记作一个活跃用户。这里“使用行为”的定义因应用而异，有的团队将启动即视作活跃，有的则需要满足启动 + 执行某种操作（如浏览过至少一个商品），还有的则索性将常驻后台的守护进行没有被杀死也统计进了活跃范畴中。因此如何计量活跃用户数，归根结底还是看团队真正追求的是什么。活跃用户数一般看“日活”（Daily Active Users， DAU）和“月活”（Monthly Active Users， MAU）。</li>
<li>升级用户数（Updated Users）：指由已装的老版本升级到新版本的用户数量。时常有人问，像QQ这样保有量已经很大的应用，为什么每天在应用市场上创造如此巨大的下载量？其中很重要的因素之一，就是将用户从老版本升级到新版本的下载行为统计了进去。</li>
<li>留存率（Retention Rate）：指用户在某段时间内开始使用应用后，经过一段时间，仍然继续使用，这部分用户占当时新增用户的比率，也就是“有多少人最后留下来了”。留存率用户衡量应用的质量和营销效果的好坏。通常新增用户如果因为真实需求而来（如从应用市场主动搜索并下载获得），则留存率较高；而因为博眼球的营销推广（尤其是有奖活动）进来的用户，留存率较低。并且，不同种类应用的留存率也有各自的基准，如游戏的首月留存率通常比社交类高，而工具类的首月留存率又比游戏高。留存率通常看次日留存率、3日留存率、7日留存率、15日留存率和30日留存率。</li>
<li>总用户数（Total Users）：指历史上所有新增用户数之和。该数字由单纯地相加获得，存在一定水分，无法体现已经流失或极不活跃的用户情况。</li>
<li>单次使用时长（Duration）：指用户从一次启动到退出应用所耗费的时间长短，用于衡量应用的黏性。应用在后台运行并不会计入其中。不同类别的应用，单次使用时长可以千差万别。工具类产品解决问题目标明确，用户完成任务之后就会立即退出，比如看一下天气、优化一下内存占用等，用几秒就可以关闭。而视频播放类应用则能持续更久，通常可达到几十分钟。</li>
<li>平均单次使用时长（Average Duration）：计算方法是某日总使用时长/该日启动数，可用于更准确地评估用户的使用状态。因为一款应用在不同时段的使用时长可能存在差别，用户早上挤地铁时的一瞥与晚间睡觉前的沉浸使用，其单次使用时长本身是不具备可比性的，只有平均之后才能用于横向比较。   使用间隔（Interval）：指连续两次使用之间的时间间隔。如果一款定位于提供每日新闻资讯的应用的使用间隔过长，则说明对用户的黏性不够强，并未培养成每日使用的习惯，只是在偶尔想起来时看一眼。这就需要在产品上下功夫，或采取一些运营手段弥补，如定时推送当日的头条新闻。</li>
<li>转化率（Conversion Rate）：指应用内特定行为目标的转化情况，如让用户点击某个按钮、播放一段视频、邀请一批好友等。</li>
<li>K因子（K-Factor）：衡量产品的病毒传播能力，计算方法为每个用户平均发出的邀请数量/收到邀请转化成新增用户的比率。如果K因子大于1，表明产品具有自我传播能力，会随着用户的使用而持续扩散。</li>
<li>每用户平均收益（Average Revenue Per User，ARPU）：简单的理解就是“能从每个用户那里收多少钱”，是衡量产品盈利能力的指标，也可用来检测不同市场渠道获取的用户质量。ARPU的通常计算方法是产品在一定时限内的收入/活跃用户数。结合单用户的获取成本，可以推断出产品是否能形成自我造血的持续发展能力。</li>
<li>每付费用户平均收益（Average Revenue Per Paid User，ARPPU）：与ARPU将收入平摊到所有用户头上不同，ARPPU只计算从所有付费用户处获取的平均收益，据此更准确地把握付费用户的支付能力、消费习惯，并有针对性地对这部分付费用户重点运营和服务。</li>
<li>月付费率（Monthly Payment Ratio，MPR）：指一个月的统计区间内付费用户占活跃用户的比例。</li>
<li>生命周期价值（Life Time Value，LTV）：用户从第一次使用产品，到最后一次使用之间，累计贡献的付费总量。</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/24/sparkkai-fa-huan-jing-da-jian/">Spark开发环境搭建</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-24T14:19:18+08:00" pubdate data-updated="true">Feb 24<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>一、Mac开发环境配置</p>

<p>1.1 安装Intellij</p>

<p>官网下载Intellij,<a href="https://www.jetbrains.com/idea/">https://www.jetbrains.com/idea/</a>.Intellji目前是Scala的主流开发工具，对Scala有很好的支持</p>

<p>1.2 安装SBT插件</p>

<p>1.3 安装Scala插件</p>

<p>1.4 引入Jar包</p>

<p>需要引入Spark相关的Jar包，下载地址：<a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a>。选择图中的版本：</p>

<p><img src="http://7xq7y8.com1.z0.glb.clouddn.com/QQ20160224-0%402x.png" alt="" /></p>

<p>将下载下来的spark-assembly-1.6.0-hadoop2.6.0.jar包引入项目:</p>

<p><img src="http://7xq7y8.com1.z0.glb.clouddn.com/QQ20160224-1%402x.png" alt="" /></p>

<p>二、编写Hello World</p>

<p>`object test {
  def main(args: Array[String]) {</p>

<pre><code>val conf = new SparkConf().setAppName("Hello").setMaster("local")
val sc = new SparkContext(conf)
val text = sc.parallelize(Seq("a", "cc", "aa", "11"))
val c = text.count()
print(c)
</code></pre>

<p>  }
}`</p>

<p>三、Spark Shell执行Spark程序</p>

<p>启动关闭Spark Shell</p>

<p>进入bin目录执行spark-shell.sh</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/23/sparkji-suan-mo-xing/">Spark计算模型</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-23T14:19:02+08:00" pubdate data-updated="true">Feb 23<span>rd</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>一、Spark程序示例</p>

<p>数据处理流水线：</p>

<pre><code>val file = sc.textFile("hdfs://xxx"); //1)输入与构造RDD

val errors=file.filter(line=&gt;line.contains("ERROR"))//2) 转换Transformation

errors.count //3)输出Action
</code></pre>

<p>整个Spark的核心：提供分布式数据结构RDD+算法（两类RDD函数支撑）</p>

<p>二、弹性分布式数据集RDD</p>

<p>弹性分布式数据集RDD可以理解为一个分布式数组，它将数据切分成不同的块，分布在整个集群中的不同节点，通过统一的元数据以及RDD进行整个数据块的管理。它主要有以下5个属性：</p>

<p>1) partition (A list of partitions)    ——数据块，它存储了所有数据块的列表</p>

<p>2) compute函数（A function for computing each split），它能够支持利用不同的RDD完成不同的运算，有的RDD完成map运算，里面可以执行自定义的函数；可以完成过滤的运算：filter</p>

<p>3）dependencies(A list of dependencies on other RDDs)：RDD的一个依赖</p>

<p>4) partitioner：在分布式的数据结构中，是对数据要通过shuffle节点间的数据网络传输，进行一个重分区。默认支持hash分区算法</p>

<p>5）preferredLocations（Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)）</p>

<p>三、RDD两类基础函数</p>

<p>1) 转化(Transformations) :</p>

<p>Transformations操作是延迟计算的。操作有：mapper,filter等。如果没有action算子，任务不会执行。</p>

<ul>
<li>map(func)：对调用map的RDD数据集中的每个element都使用func，然后返回一个新的RDD，这个返回的数据集是分布式的数据集。</li>
<li>filter(func):对调用filter的RDD数据集中的每个元素都使用func，然后返回一个包含使用func为true的元素构成的RDD</li>
<li>reduceByKey(func,[numTasks])：就是用一个给定的reduce func再作用在groupByKey产生的(K, Seq[V])，比如求和，求平均数，类似于SQL中的group by操作</li>
</ul>


<p>2）行动(Actions)</p>

<p>Actions算子会触发Spark提交作业（Job），并将数据输出Spark系统</p>

<ul>
<li>reduce(func)：说白了就是聚集，但是传入的函数是两个参数输入返回一个值。这个函数必须是满足交换律和结合律的</li>
<li>collect()：一般在filter或者足够小的结果的时候，再用collect封装返回一个数组</li>
<li>count()：返回的是dataset中的element的个数</li>
<li>first()：返回的是datasetz中的第一个元素</li>
<li>take(n)：返回前n个elements，这个是driver program返回的</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/02/sparkjian-jie-yu-ji-suan-mo-xing/">Spark简介</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-02T16:25:19+08:00" pubdate data-updated="true">Feb 2<span>nd</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Saprk是基于内存计算的大数据分布式计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。</p>

<p>Spark特点：</p>

<ul>
<li>分布式计算</li>
<li>内存计算</li>
<li>容错，checkpoint</li>
<li>多计算范式</li>
</ul>


<p>Spark于2009年诞生于加州大学伯克利分校AMPLab。目前，已经成为Apache软件基金会旗下顶级开源项目。</p>

<p>官网：<a href="http://spark.apache.org/">http://spark.apache.org/</a></p>

<h4>Spark简介-历史</h4>

<ul>
<li>2009年：Spark诞生于AMPLab</li>
<li>2010年：开源</li>
<li>2013年6月：Apache孵化器项目</li>
<li>2014年2月：Apache顶级项目</li>
<li>Now：Contributors > 450 人</li>
</ul>


<h4>Saprk简介-BDAS生态系统</h4>

<p><img src="http://7xq7y8.com1.z0.glb.clouddn.com/QQ20160202-0%402x.png" alt="BDAS生态系统" /></p>

<ul>
<li>Mesos作为资源管理框架，类似于yarn，负责资源调度和管理</li>
<li>Tachyon，分布式内存文件系统，缓存数据并进行快速的数据读写</li>
<li>Spark，核心计算引擎，将任务并行化，在集群中进行大规模数据运算</li>
<li>SparkStreaming，流式计算引擎，将输入数据切分成小的批次，对每个批次采用Spark计算范式进行计算</li>
<li>SparkSQL, SQL ON hadoop系统，能够提供交互式查询以及报表查询等基本的查询功能，并且能够通过JDBC等接口进行调用</li>
<li>GraphX，图计算引擎，能够完成大规模图运算，比例PageRank算法。</li>
<li>MLlib：机器学习库，聚类、分类以及推荐等机器学习算法。</li>
</ul>


<h4>Spark简介——专有系统局限</h4>

<ul>
<li><p>重复开发</p>

<p>  例如，生产环境中部署了Storm做流式计算，Mahout做机器学习，两套系统都需要开发自己的内存管理以及任务调度</p></li>
<li><p>系统组合</p>

<p>  不同的系统之间要进行数据的输入和输出，需要对数据输入和输出的格式进行约定</p></li>
<li><p>专有系统适用范围局限</p>

<p>  例如，Storm比较适合做流式计算，GraphX比较适合做图计算</p></li>
<li><p>资源分配与管理</p>

<p>  两套系统分别启动自己的进程占用相应的CPU资源，这样造成资源不能很好的共享以及不容易管理</p></li>
</ul>


<h4>Spark简介-优势</h4>

<ul>
<li><p>计算范式支持</p>

<p>  打造全栈多计算范式的高效数据数据流水线</p></li>
<li><p>处理速度</p>

<p>  轻量级快速处理大数据，Saprk的代码量很小，核心代码只有5W行</p></li>
<li><p>易用性</p>

<p>  Spark非常易于使用，分布式RDD抽象，Spark支持多语言，Scala，Java，Python</p></li>
<li><p>兼容性</p>

<p>  与HDFS等存储层兼容</p></li>
<li><p>社区活跃度</p>

<p>  社区活跃度高</p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/25/sparkzhong-yong-sparksqlcao-zuo-hive/">spark中用SparkSql操作Hive</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-25T17:03:07+08:00" pubdate data-updated="true">Jan 25<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://spark.apache.org/">Spark</a>中操作<a href="https://hive.apache.org/">hive</a>，需要借助SaprkSQL工具包。SparkSQL中集成了对JSON串，hive，hdfs以及关系型数据库MySQL等的操作。SparkSQL的数据结构是高度自定义的DataFrame，DataFrame实现了结构化数据源与RDD之间的便利操作。</p>

<p>hive从0.14版本开始支持Insert语句(只支持ACID特性的表)，在更早的版本，Hive几乎只支持Load操作（从本地或者hdfs），参考链接：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingvaluesintotablesfromSQL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingvaluesintotablesfromSQL</a></p>

<pre><code>Standard Syntax:
INSERT INTO TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] VALUES values_row [, values_row ...]

Where values_row is:
( value [, value ...] )
where a value is either null or any valid SQL literal
</code></pre>

<p>Examples</p>

<pre><code>CREATE TABLE students (name VARCHAR(64), age INT, gpa DECIMAL(3, 2)) CLUSTERED BY (age) INTO 2 BUCKETS STORED AS ORC;

INSERT INTO TABLE students VALUES ('fred flintstone', 35, 1.28), ('barney rubble', 32, 2.32);


CREATE TABLE pageviews (userid VARCHAR(64), link STRING, came_from STRING) PARTITIONED BY (datestamp STRING) CLUSTERED BY (userid) INTO 256 BUCKETS STORED AS ORC;

INSERT INTO TABLE pageviews PARTITION (datestamp = '2014-09-23') VALUES ('jsmith', 'mail.com', 'sports.com'), ('jdoe', 'mail.com', null);

INSERT INTO TABLE pageviews PARTITION (datestamp) VALUES ('tjohnson', 'sports.com', 'finance.com', '2014-09-23'), ('tlee', 'finance.com', null, '2014-09-21');
</code></pre>

<p>用SparkSQL向hive中插入数据，需要将数据转换成DataFrame数据结构，DataFrame提供了简便的insert操作。</p>

<p>DataFrame支持由RDD创建，参考链接：<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#creating-dataframes">http://spark.apache.org/docs/latest/sql-programming-guide.html#creating-dataframes</a>：</p>

<pre><code>public static class Person implements Serializable {
private String name;
private int age;
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
public int getAge() {
return age;
}
public void setAge(int age) {
this.age = age;
}
}

// sc is an existing JavaSparkContext.
SQLContext sqlContext = new org.apache.spark.sql.SQLContext(sc);

// Load a text file and convert each line to a JavaBean.
JavaRDD&lt;Person&gt; people = sc.textFile("examples/src/main/resources/people.txt").map(
new Function&lt;String, Person&gt;() {
public Person call(String line) throws Exception {
  String[] parts = line.split(",");

  Person person = new Person();
  person.setName(parts[0]);
  person.setAge(Integer.parseInt(parts[1].trim()));

  return person;
}
});

// Apply a schema to an RDD of JavaBeans and register it as a table.
DataFrame schemaPeople = sqlContext.createDataFrame(people, Person.class);
schemaPeople.registerTempTable("people");

// SQL can be run over RDDs that have been registered as tables.
DataFrame teenagers = sqlContext.sql("SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19")

// The results of SQL queries are DataFrames and support all the normal RDD operations.
// The columns of a row in the result can be accessed by ordinal.
List&lt;String&gt; teenagerNames = teenagers.javaRDD().map(new Function&lt;Row, String&gt;() {
public String call(Row row) {
return "Name: " + row.getString(0);
}
}).collect();
</code></pre>

<p>将数据插入hive：</p>

<pre><code>schemaPeople.insertInto("person")
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/03/stormde-tuo-bu-jobde-dong-tai-diao-du-you-hua/">storm的拓扑Job的动态调度优化</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-03T10:58:59+08:00" pubdate data-updated="true">Jul 3<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>前一段时间跟一个小伙伴聊到storm的拓扑动态分配的算法——如何能够根据storm的集群状态去最优化分配每个拓扑Job 。</p>

<p>下面先说一下具体的问题：</p>

<p>在实际使用场景中，每个拓扑Job所需要的资源都是动态变化的，有的Job在某个点需要的slot多，而在其它时间点需要的slot少。如何设计一个有效的动态算法去均衡每个拓扑Job呢？</p>

<p>首先想到的是Hadoop中的雅虎调度器或许能够解决这个问题，后来想想，Hadoop与Storm有着本质的区别，Hadoop的每个MapReduce作业总有跑完的一天，而拓扑Job却是7 × 24运行的拓扑流，并不能简单的用队列和优先级来决定每个拓扑Job所需要的slots。</p>

<p>下面谈谈自己想到的方案：</p>

<p>这个方案借鉴于HashMap的实现原理：我们都知道HashMap在初始化时都有一个固定的大小，然后随着容量的增大，HashMap通过一个增长因子来逐渐增加容量大小。</p>

<p>Storm的Job调度原理也一样，在初始化时给定一个固定的slot槽，然后通过ack时间判断是否Job需要增加slot，同时给增加slot设置一个增长因子,给该Job增加所需要的slot槽。此时，会出现下面几个问题：</p>

<p>1、如果根据增长因子计算需要的slot槽，发现剩下的slot不够了，怎么办？</p>

<p>2、什么时候适合把过剩slot槽释放掉？</p>

<p>先解决这两个问题：</p>

<p>第一个问题比较简单，如果剩下的slot槽不够了，只能把剩下的slot槽都分配给该Job。</p>

<p>第二个问题涉及到的问题比较多，如果根据ack时间去决定，当ack时间足够短的时候，根据增长因子释放掉增加的slot，而如果出现当释放完slot之后，ack又不能满足需求，此时就会进入一个死循环，不断的在分配slot。这种问题一般是增长因子出现了问题。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/03/atof-jiang-zi-fu-chuan-zhuan-hua-wei-fu-dian-shu-de-javashi-xian/">atof(将字符串转化为浮点数的Java实现)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-03T09:38:20+08:00" pubdate data-updated="true">Jul 3<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>atof，是C语言中的一个字符串转化为浮点数的函数，在Java在也有一个对应的实现，就是大家所熟悉的Double.parseDouble(String s)函数。</p>

<p>既然是讲atof的Java实现，肯定脱离不开C语言的实现，字符串转化为浮点数整个的算法核心只有一个，如何将字符&#8217;0&#8217;~&lsquo;9&#8217;转化为计算机能识别的数字0~9，而在C语言中有一个很简单的转化方式：int x = (char)c &ndash; &#8216;0&rsquo;; 剩下的就是一些异常处理以及如果有效的得到该字符串的位数。</p>

<p>本文核心是想理解Java的实现，借此可以了解Java将字符串转为为浮点数的原理，通过这些代码可以看到，代码编写人注意了每一行代码的变量声明，以及if的逻辑控制提高效率：</p>

<pre><code>public strictfp double doubleValue(){
    int     kDigits = Math.min( nDigits, maxDecimalDigits+1 );
    long    lValue;
    double  dValue;
    double  rValue, tValue;

    // First, check for NaN and Infinity values
    if(digits == infinity || digits == notANumber) {
        if(digits == notANumber)
            return Double.NaN;
        else
            return (isNegative?Double.NEGATIVE_INFINITY:Double.POSITIVE_INFINITY);
    }
    else {
        if (mustSetRoundDir) {
            roundDir = 0;
        }
        /*
         * convert the lead kDigits to a long integer.
         */
        // (special performance hack: start to do it using int)
        int iValue = (int)digits[0]-(int)'0';
        int iDigits = Math.min( kDigits, intDecimalDigits );
        for ( int i=1; i &lt; iDigits; i++ ){
            iValue = iValue*10 + (int)digits[i]-(int)'0';
        }
        lValue = (long)iValue;
        for ( int i=iDigits; i &lt; kDigits; i++ ){
            lValue = lValue*10L + (long)((int)digits[i]-(int)'0');
        }
        dValue = (double)lValue;
        int exp = decExponent-kDigits;
        /*
         * lValue now contains a long integer with the value of
         * the first kDigits digits of the number.
         * dValue contains the (double) of the same.
         */

        if ( nDigits &lt;= maxDecimalDigits ){
            /*
             * possibly an easy case.
             * We know that the digits can be represented
             * exactly. And if the exponent isn't too outrageous,
             * the whole thing can be done with one operation,
             * thus one rounding error.
             * Note that all our constructors trim all leading and
             * trailing zeros, so simple values (including zero)
             * will always end up here
             */
            if (exp == 0 || dValue == 0.0)
                return (isNegative)? -dValue : dValue; // small floating integer
            else if ( exp &gt;= 0 ){
                if ( exp &lt;= maxSmallTen ){
                    /*
                     * Can get the answer with one operation,
                     * thus one roundoff.
                     */
                    rValue = dValue * small10pow[exp];
                    if ( mustSetRoundDir ){
                        tValue = rValue / small10pow[exp];
                        roundDir = ( tValue ==  dValue ) ? 0
                            :( tValue &lt; dValue ) ? 1
                            : -1;
                    }
                    return (isNegative)? -rValue : rValue;
                }
                int slop = maxDecimalDigits - kDigits;
                if ( exp &lt;= maxSmallTen+slop ){
                    /*
                     * We can multiply dValue by 10^(slop)
                     * and it is still "small" and exact.
                     * Then we can multiply by 10^(exp-slop)
                     * with one rounding.
                     */
                    dValue *= small10pow[slop];
                    rValue = dValue * small10pow[exp-slop];

                    if ( mustSetRoundDir ){
                        tValue = rValue / small10pow[exp-slop];
                        roundDir = ( tValue ==  dValue ) ? 0
                            :( tValue &lt; dValue ) ? 1
                            : -1;
                    }
                    return (isNegative)? -rValue : rValue;
                }
                /*
                 * Else we have a hard case with a positive exp.
                 */
            } else {
                if ( exp &gt;= -maxSmallTen ){
                    /*
                     * Can get the answer in one division.
                     */
                    rValue = dValue / small10pow[-exp];
                    tValue = rValue * small10pow[-exp];
                    if ( mustSetRoundDir ){
                        roundDir = ( tValue ==  dValue ) ? 0
                            :( tValue &lt; dValue ) ? 1
                            : -1;
                    }
                    return (isNegative)? -rValue : rValue;
                }
                /*
                 * Else we have a hard case with a negative exp.
                 */
            }
        }

        /*
         * Harder cases:
         * The sum of digits plus exponent is greater than
         * what we think we can do with one error.
         *
         * Start by approximating the right answer by,
         * naively, scaling by powers of 10.
         */
        if ( exp &gt; 0 ){
            if ( decExponent &gt; maxDecimalExponent+1 ){
                /*
                 * Lets face it. This is going to be
                 * Infinity. Cut to the chase.
                 */
                return (isNegative)? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
            }
            if ( (exp&amp;15) != 0 ){
                dValue *= small10pow[exp&amp;15];
            }
            if ( (exp&gt;&gt;=4) != 0 ){
                int j;
                for( j = 0; exp &gt; 1; j++, exp&gt;&gt;=1 ){
                    if ( (exp&amp;1)!=0)
                        dValue *= big10pow[j];
                }
                /*
                 * The reason for the weird exp &gt; 1 condition
                 * in the above loop was so that the last multiply
                 * would get unrolled. We handle it here.
                 * It could overflow.
                 */
                double t = dValue * big10pow[j];
                if ( Double.isInfinite( t ) ){
                    /*
                     * It did overflow.
                     * Look more closely at the result.
                     * If the exponent is just one too large,
                     * then use the maximum finite as our estimate
                     * value. Else call the result infinity
                     * and punt it.
                     * ( I presume this could happen because
                     * rounding forces the result here to be
                     * an ULP or two larger than
                     * Double.MAX_VALUE ).
                     */
                    t = dValue / 2.0;
                    t *= big10pow[j];
                    if ( Double.isInfinite( t ) ){
                        return (isNegative)? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
                    }
                    t = Double.MAX_VALUE;
                }
                dValue = t;
            }
        } else if ( exp &lt; 0 ){
            exp = -exp;
            if ( decExponent &lt; minDecimalExponent-1 ){
                /*
                 * Lets face it. This is going to be
                 * zero. Cut to the chase.
                 */
                return (isNegative)? -0.0 : 0.0;
            }
            if ( (exp&amp;15) != 0 ){
                dValue /= small10pow[exp&amp;15];
            }
            if ( (exp&gt;&gt;=4) != 0 ){
                int j;
                for( j = 0; exp &gt; 1; j++, exp&gt;&gt;=1 ){
                    if ( (exp&amp;1)!=0)
                        dValue *= tiny10pow[j];
                }
                /*
                 * The reason for the weird exp &gt; 1 condition
                 * in the above loop was so that the last multiply
                 * would get unrolled. We handle it here.
                 * It could underflow.
                 */
                double t = dValue * tiny10pow[j];
                if ( t == 0.0 ){
                    /*
                     * It did underflow.
                     * Look more closely at the result.
                     * If the exponent is just one too small,
                     * then use the minimum finite as our estimate
                     * value. Else call the result 0.0
                     * and punt it.
                     * ( I presume this could happen because
                     * rounding forces the result here to be
                     * an ULP or two less than
                     * Double.MIN_VALUE ).
                     */
                    t = dValue * 2.0;
                    t *= tiny10pow[j];
                    if ( t == 0.0 ){
                        return (isNegative)? -0.0 : 0.0;
                    }
                    t = Double.MIN_VALUE;
                }
                dValue = t;
            }
        }

        /*
         * dValue is now approximately the result.
         * The hard part is adjusting it, by comparison
         * with FDBigInt arithmetic.
         * Formulate the EXACT big-number result as
         * bigD0 * 10^exp
         */
        FDBigInt bigD0 = new FDBigInt( lValue, digits, kDigits, nDigits );
        exp   = decExponent - nDigits;

        correctionLoop:
        while(true){
            /* AS A SIDE EFFECT, THIS METHOD WILL SET THE INSTANCE VARIABLES
             * bigIntExp and bigIntNBits
             */
            FDBigInt bigB = doubleToBigInt( dValue );

            /*
             * Scale bigD, bigB appropriately for
             * big-integer operations.
             * Naively, we multiply by powers of ten
             * and powers of two. What we actually do
             * is keep track of the powers of 5 and
             * powers of 2 we would use, then factor out
             * common divisors before doing the work.
             */
            int B2, B5; // powers of 2, 5 in bigB
            int     D2, D5; // powers of 2, 5 in bigD
            int Ulp2;   // powers of 2 in halfUlp.
            if ( exp &gt;= 0 ){
                B2 = B5 = 0;
                D2 = D5 = exp;
            } else {
                B2 = B5 = -exp;
                D2 = D5 = 0;
            }
            if ( bigIntExp &gt;= 0 ){
                B2 += bigIntExp;
            } else {
                D2 -= bigIntExp;
            }
            Ulp2 = B2;
            // shift bigB and bigD left by a number s. t.
            // halfUlp is still an integer.
            int hulpbias;
            if ( bigIntExp+bigIntNBits &lt;= -expBias+1 ){
                // This is going to be a denormalized number
                // (if not actually zero).
                // half an ULP is at 2^-(expBias+expShift+1)
                hulpbias = bigIntExp+ expBias + expShift;
            } else {
                hulpbias = expShift + 2 - bigIntNBits;
            }
            B2 += hulpbias;
            D2 += hulpbias;
            // if there are common factors of 2, we might just as well
            // factor them out, as they add nothing useful.
            int common2 = Math.min( B2, Math.min( D2, Ulp2 ) );
            B2 -= common2;
            D2 -= common2;
            Ulp2 -= common2;
            // do multiplications by powers of 5 and 2
            bigB = multPow52( bigB, B5, B2 );
            FDBigInt bigD = multPow52( new FDBigInt( bigD0 ), D5, D2 );
            //
            // to recap:
            // bigB is the scaled-big-int version of our floating-point
            // candidate.
            // bigD is the scaled-big-int version of the exact value
            // as we understand it.
            // halfUlp is 1/2 an ulp of bigB, except for special cases
            // of exact powers of 2
            //
            // the plan is to compare bigB with bigD, and if the difference
            // is less than halfUlp, then we're satisfied. Otherwise,
            // use the ratio of difference to halfUlp to calculate a fudge
            // factor to add to the floating value, then go 'round again.
            //
            FDBigInt diff;
            int cmpResult;
            boolean overvalue;
            if ( (cmpResult = bigB.cmp( bigD ) ) &gt; 0 ){
                overvalue = true; // our candidate is too big.
                diff = bigB.sub( bigD );
                if ( (bigIntNBits == 1) &amp;&amp; (bigIntExp &gt; -expBias+1) ){
                    // candidate is a normalized exact power of 2 and
                    // is too big. We will be subtracting.
                    // For our purposes, ulp is the ulp of the
                    // next smaller range.
                    Ulp2 -= 1;
                    if ( Ulp2 &lt; 0 ){
                        // rats. Cannot de-scale ulp this far.
                        // must scale diff in other direction.
                        Ulp2 = 0;
                        diff.lshiftMe( 1 );
                    }
                }
            } else if ( cmpResult &lt; 0 ){
                overvalue = false; // our candidate is too small.
                diff = bigD.sub( bigB );
            } else {
                // the candidate is exactly right!
                // this happens with surprising frequency
                break correctionLoop;
            }
            FDBigInt halfUlp = constructPow52( B5, Ulp2 );
            if ( (cmpResult = diff.cmp( halfUlp ) ) &lt; 0 ){
                // difference is small.
                // this is close enough
                if (mustSetRoundDir) {
                    roundDir = overvalue ? -1 : 1;
                }
                break correctionLoop;
            } else if ( cmpResult == 0 ){
                // difference is exactly half an ULP
                // round to some other value maybe, then finish
                dValue += 0.5*ulp( dValue, overvalue );
                // should check for bigIntNBits == 1 here??
                if (mustSetRoundDir) {
                    roundDir = overvalue ? -1 : 1;
                }
                break correctionLoop;
            } else {
                // difference is non-trivial.
                // could scale addend by ratio of difference to
                // halfUlp here, if we bothered to compute that difference.
                // Most of the time ( I hope ) it is about 1 anyway.
                dValue += ulp( dValue, overvalue );
                if ( dValue == 0.0 || dValue == Double.POSITIVE_INFINITY )
                    break correctionLoop; // oops. Fell off end of range.
                continue; // try again.
            }

        }
        return (isNegative)? -dValue : dValue;
    }
}
</code></pre>

<p>上面就是整个实现的源代码，之所以列出来，省的各位去找了，下面就来一行行解读：</p>

<p>首先跟C语言中的实现一样，去掉了字符串前后的空格：</p>

<pre><code>in = in.trim()
</code></pre>

<p>判断是否为空的字符串：</p>

<pre><code>int l = in.length();
if (l == 0) throw new NumberFormatException("empty String");
</code></pre>

<p>取出第一个字符，判断是否为正负数：</p>

<pre><code>int i = 0;
        switch (c = in.charAt(i)) {
            case '-':
                isNegative = true;
                //FALLTHROUGH
            case '+':
                i++;
                signSeen = true;
        }
</code></pre>

<p>检查是否为Infinity（无穷大）或者NaN（不明确的数值结果，一般被除数为0会出现这个结果）</p>

<pre><code>c = in.charAt(i);

if (c == 'N' || c == 'I');
</code></pre>

<p>如果既不是Infinity或者NaN，则检查是为十六进制浮点数</p>

<pre><code>else if (c == '0');
</code></pre>

<p>之后就是把字符串中的每个字符拆解出来放到array中，</p>

<p>Java提供了一个方法，将字符array转化为数字，即doubleValue(),</p>

<p>从doubleValue()中可以看到</p>

<p>int iValue = (int)digits[0]&ndash;(int)&lsquo;0&rsquo;;</p>

<p><strong>直接通过了强制类型转换进行数值的转换</strong>，剩下的任务就是异常判断以及是否为科学计数法。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/27/nginxyou-hua-pian-zhi-linux-nei-he-can-shu-de-you-hua/">nginx优化篇之Linux 内核参数的优化</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-27T09:43:24+08:00" pubdate data-updated="true">May 27<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>由于默认的Linux内核参数考虑的是最通用的场景，这明显不符合用于支持高并发访问的Web服务器的定义，所以需要修改Linux内核参数，使得Nginx可以拥有更高的性能。</p>

<p>在优化内核时，可以做的事件很多，不过，我们通常会根据业务特点来进行调整，当Nginx作为静态Web内容服务器、反向代理服务器或是提供图片缩略功能（实时压缩图片）的服务器时，其内核参数的调整都是不同的。这里只针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单说明。</p>

<p>首先，需要修改/etc/sysctl.conf来更改内核参数，例如，最常用的配置：</p>

<pre><code>#原有字段
net.ipv4.tcp_syncookies = 1
#新增字段
fs.file-max = 999999
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.ip_local_port_range = 1024 61000
net.ipv4.tcp_rmem = 10240 87380 12582912
net.ipv4.tcp_wmem = 10240 87380 12582912
net.core.netdev_max_backlog = 8096
net.core.rmem_default = 6291456
net.core.wmem_default = 6291456
net.core.rmem_max = 12582912
net.core.wmem_max = 12582912
net.ipv4.tcp_max_syn_backlog = 1024
</code></pre>

<p><strong>然后执行sysctl -p命令，使上述参数生效。</strong></p>

<p><strong>上面的参数意义解释如下：</strong></p>

<p><strong>fs.file-max = 999999：这个参数表示进程（比如一个worker进程）可以同时打开的最大句柄数，这个参数直线限制最大并发连接数，需根据实际情况配置。</strong></p>

<p><strong>net.ipv4.tcp_tw_reuse = 1：这个参数设置为1，表示允许将TIME-WAIT状态的socket重新用于新的TCP连接，这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。</strong></p>

<p><strong>net.ipv4.tcp_keepalive_time = 600：这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，若将其设置的小一些，可以更快地清理无效的连接。</strong></p>

<p><strong>net.ipv4.tcp_fin_timeout = 30：这个参数表示当服务器主动关闭连接时，socket保持在FIN-WAIT-2状态的最大时间。</strong></p>

<p><strong>net.ipv4.tcp_max_tw_buckets = 5000：这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。该参数默认为180 000，过多的TIME_WAIT套接字会使Web服务器变慢。</strong></p>

<p><strong>net.ipv4.tcp_max_syn_backlog = 1024：这个参数标示TCP三次握手建立阶段接受SYN请求队列的最大长度，默认为1024，将其设置得大一些可以使出现Nginx繁忙来不及accept新连接的情况时，Linux不至于丢失客户端发起的连接请求。</strong></p>

<p><strong>net.ipv4.ip_local_port_range = 1024 61000：这个参数定义了在UDP和TCP连接中本地（不包括连接的远端）端口的取值范围。</strong></p>

<p><strong>net.ipv4.tcp_rmem = 10240 87380 12582912：这个参数定义了TCP接受缓存（用于TCP接受滑动窗口）的最小值、默认值、最大值。</strong></p>

<p><strong>net.ipv4.tcp_wmem = 10240 87380 12582912：这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值、默认值、最大值。</strong></p>

<p><strong>net.core.netdev_max_backlog = 8096：当网卡接受数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。这个参数表示该队列的最大值。</strong></p>

<p><strong>net.core.rmem_default = 6291456：这个参数表示内核套接字接受缓存区默认的大小。</strong></p>

<p><strong>net.core.wmem_default = 6291456：这个参数表示内核套接字发送缓存区默认的大小。</strong></p>

<p><strong>net.core.rmem_max = 12582912：这个参数表示内核套接字接受缓存区的最大大小。</strong></p>

<p><strong>net.core.wmem_max = 12582912：这个参数表示内核套接字发送缓存区的最大大小。</strong></p>

<p>net.ipv4.tcp_syncookies = 1：该参数与性能无关，用于解决TCP的SYN攻击。</p>

<p><strong>注意：滑动窗口的大小与套接字缓存区会在一定程度上影响并发连接的数目。每个TCP连接都会为维护TCP滑动窗口而消耗内存，这个窗口会根据服务器的处理速度收缩或扩张。</strong></p>

<p><strong>参数net.core.wmem_max = 12582912的设置，需要平衡物理内存的总大小、Nginx并发处理的最大连接数量而确定。当然，如果仅仅为了提供并发量使服务器不出现Out Of Memory问题而去降低滑动窗口大小，那么并不合适，因为滑动窗过小会影响大数据量的传输速度。net.core.rmem_default = 6291456、net.core.wmem_default = 6291456、net.core.rmem_max = 12582912和net.core.wmem_max = 12582912这4个参数的设置需要根据我们的业务特性以及实际的硬件成本来综合考虑。</strong></p>

<p><strong>Nginx并发处理的最大连接量：由nginx.conf中的work_processes和work_connections参数决定。</strong></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/25/capacityschedulerdiao-du-suan-fa/">CapacityScheduler调度算法</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-25T17:42:54+08:00" pubdate data-updated="true">May 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本文描述了Hadoop中的Capacity Scheduler的实现算法，Capacity Scheduler是由Yahoo贡献的，主要是解决HADOOP-3421中提出的，在调度器上完成HOD（Hadoop On Demand）功能，克服已有HOD的性能低效的缺点。它适合于多用户共享集群的环境的调度器。本文解析的计算能力调度器属于Hadoop 0.21.0。</p>

<h2>一、计算能力调度器介绍</h2>

<p>Capacity Scheduler支持以下特性：</p>

<ul>
<li>(1) <strong>计算能力保证。</strong>支持多个队列，某个作业可被提交到某一个队列中。每个队列会配置一定比例的计算资源，且所有提交到队列中的作业共享该队列中的资源。</li>
<li>(2) <strong>灵活性。</strong>空闲资源会被分配给那些未达到资源使用上限的队列，当某个未达到资源的队列需要资源时，一旦出现空闲资源，便会分配给他们。</li>
<li>(3) <strong>支持优先级。</strong>队列支持作业优先级调度（默认是FIFO）。</li>
<li>(4) <strong>多重租赁。</strong>综合考虑多种约束防止单个作业、用户或者队列独占队列或者集群中的资源。</li>
<li>(5) <strong>基于资源的调度。</strong> 支持资源密集型作业，允许作业使用的资源量高于默认值，进而可容纳不同资源需求的作业。不过，当前仅支持内存资源的调度。</li>
</ul>


<h2>二、Capacity Scheduler概述</h2>

<p>Capacity Scheduling是由雅虎提出的作业调度算法，它提供了类似于Fair Scheduling算法的功能，但是在设计与实现上两者在很多方面存在着差别。</p>

<p>在Capacity Scheduling算法中，可以定义多个作业队列。当作业被提交时，它将被直接放入到一个队列中。每个队列都可以通过配置获得一定数量的TaskTracker资源用于处理Map操作和Reduce操作。调度算法将按照配置文件为队列分配相应的计算资源量。同Fair Scheduling算法近似，为了提高资源利用率，对于已经被分配但是尚处于空闲状态的资源，各个队列为分享它们。当没有能够按照设定数值获得足够资源量的队列中增加了作业压力时，之前那些曾经分配给它但又被别的队列所占用的资源会在完成当前任务后立即配给回它应属的队列。由此可以看出，Capacity Scheduling算法的思路是为各个队列中的作业模拟出具有指定计算能力的独立的Hadoop集群资源，而不像Fair Scheduling算法那样试图在所有作业之间实现公平的资源分享。</p>

<p>Capacity Scheduling算法在每个队列中采用的调度策略是带有优先级的FIFO算法，优先级高的作业可以在优先级低的作业之前访问队列资源。Capacity Scheduling算法不支持优先级抢占，一旦一个作业开始执行，那么在执行完成之前它所使用的资源是不会被有更高优先级的作业夺走的。另外，同属于同一用户的作业不能出现独占资源的情况，为了达到这一目的，Capacity Scheduling算法对队列中同一用户提交的作业能够获得的资源百分比进行了强制限定。</p>

<p>在Capacity Scheduling算法的具体实现中，最关键的也是如何挑选合适的作业去执行。当系统中出现了空闲的TaskTracker，算法会首先选择一个具有最多空闲空间的队列，这是通过计算队列中正在运行的任务数与其分得的计算资源之间的比值是否最低来判断的。一旦一个队列被选中，调度算法就会按照作业的优先级和提交时间顺序进行选择。在选择作业的时候，还需要关注作业所属的用户是否已经超出了他所能使用的资源限制，如果是的话那么相关的作业都不能被选中。</p>

<p>此外，Capacity Scheduling算法还能够有效地对Hadoop集群的内存资源进行管理，以支持内存密集型应用。如果一个作业内存资源需求较高，那么调度算法就要保证将该作业的相关任务指派到具有充足内存资源的TaskTracker上执行，以避免任务由于内存资源不足而无法执行。因此，在作业选择的过程中，Capacity Scheduling算法还需要检查空闲TaskTracker上的内存资源是否能够满足作业的内存需求。TaskTracker上的空闲资源量的数值可以通过TaskTracker的内存资源总量减去当前已经使用的内存偏移量得到，而后者是包含在TaskTracker向JobTracker发送的周期性心跳信息中。</p>

<h2>三、Capacity Scheduler调度算法源码解析</h2>

<p>下面对Capacity Scheduler调度算法的源码进行详细的拆解，Capacity Scheduler的整个类图如图3.1。</p>

<p><img src="/images/ClassDiagram1.jpg"></p>

<p>图3.1 Capacity Scheduler调度算法的整个类图</p>

<h3>3.1 TaskSchedulingMgr类</h3>

<h4>3.1.1 TaskSchedulingMgr类的成员和方法</h4>

<p>TaskSchedulingMgr是管理任务调度的抽象类，包括如下成员：</p>

<pre><code>protected CapacityTaskScheduler scheduler;
protected TaskType type = null;
</code></pre>

<p>其中，scheduler是调度器对象，在构造函数中传入；type代表任务类型，在TaskSchedulingMgr的实现类MapSchedulingMgr和ReduceSchedulingMgr中分别取值为TaskType.Map和TaskType.Reduce。</p>

<p>TaskSchedulingMgr提供了如下抽象方法：</p>

<pre><code>obtainNewTask(TaskTrackerStatus taskTracker,JobInProgress job);
getClusterCapacity();
getTSC(QueueSchedulingContext qsc);
hasSpeculativeTask(JobInProgress job,TaskTrackerStatus tts);
</code></pre>

<p>抽象方法到它的实现类去讨论。</p>

<p>TaskSchedulingMgr的其它普通方法：</p>

<pre><code>getOrderedQueues()
</code></pre>

<p>返回根据队列比较器排好序的队列，主要用来调试。</p>

<pre><code>getOrderedJobQueues()
</code></pre>

<p>获取排好序的作业队列。</p>

<pre><code>isUserOverLimit(JobInProgress j,QueueSchedulingContext qsc)
</code></pre>

<p>通过调用本地的getTSC()方法，获得TaskSchedulingContext类型的变量，提取TaskSchedulingContext中的参数，比较被占用的槽数是否小于实际可用的槽数，如是，则currentCapacity=实际可用的槽数；否则，currentCapacity=被占用的槽数+TaskDataView.getTaskDataView(type).getSlotsPerTask(j)。</p>

<p>TaskDataView类中的getTaskDataView()方法，该方法根据Task的类型是Map还是Reduce，分别获得一个TaskDataView类型的变量，并返回，然后通过job调用getSlotsPerTask()方法。</p>

<pre><code>int limit = Math.max((int) (Math.ceil((double) currentCapacity/ (double) qsc.getNumJobsByUser().size())),(int) (Math.ceil((double) (qsc.getUlMin() * currentCapacity) / 100.0)));
</code></pre>

<p>用户的ID：<code>String user = j.getProfile().getUser();</code></p>

<p>如果被该用户占用的槽数>= limit，写入日志，返回True。</p>

<pre><code>getTaskFromQueue(TaskTracker taskTracker,QueueSchedulingContext qsi)
</code></pre>

<p>这个方法从一个队列中取出一个task，返回的TaskLookupResult对象包含：</p>

<pre><code>private LookUpStatus lookUpStatus;
private Task task;
</code></pre>

<p>其中task才是关键信息，当然，task可能为空。具体的实现逻辑如图3.2。</p>

<ul>
<li>在队列中的选一个job，检查是否是RUNNING状态的；如果不是，重复1),否则继续；</li>
<li>检查队列是否超出最大slot限制，或者用户的slot占有量是否超过限定，如果是则回到1),否则继续；</li>
<li>检查tasktracker是否能满足作业的内存需求，如果满足则从作业中挑选一个任务,如代码：</li>
<li><code>Task t = obtainNewTask(taskTrackerStatus, j)</code>;</li>
<li>obtainNewTask()函数负责从job中未运行的任务挑选一个，该函数的具体细节容稍后讨论。 如果没能从job中找到适合的任务，则回到1)，否则成功，返回结果，结束。</li>
</ul>


<p><img src="/images/从队列中挑选task.jpg"></p>

<p>图3.2 从队列中挑选task</p>

<p>如果TaskTracker的内存不能满足作业的内存需求，那么调度器会判断该作业是否有待运行的任务或者保留的TaskTracker是否足够。如果是则回到（1），否则，将该tasktracker保留，退出函数。这里有一个机制：</p>

<p>CapacitySecheduler在调度过程中考虑作业的内存需求，但是，当TaskTracker内存无法满足Job的内存需求时，系统不会把它直接放弃该TaskTracker，而是将它保留给该作业，也就是将该作业的TaskTracker的slot登记到Job的名下，这样做是为了使该作业不至于饿死。</p>

<pre><code>assignTasks(TaskTracker taskTracker)
</code></pre>

<p>为TaskTracker分配task，分两种情况，如图3.3。</p>

<p><img src="/images/assignTasks.jpg"></p>

<p>图3.3 为TaskTracker分配task</p>

<p>第一种情况，看TaskTracker是否已经被预定了：</p>

<pre><code>JobInProgress job = taskTracker.getJobForFallowSlot(type);
</code></pre>

<p>如果job不为空，这表示TaskTracker的slot被job预定了，这时做以下工作：</p>

<p>如果availableSlots大于等于每个task所需的slot数，那么TaskTracker释放预留的slot，并从job中挑选一个任务在TaskTracker上运行，退出。否则，重新预留TaskTracker的slot给job，并返回内存匹配失败的TaskLoogupResult对象。</p>

<p>第二种情况，如果TaskTracker没有被预留，那么，从备选的队列集合中寻找适合的队列，并从队列中挑选适合的task，选出来的task必须是三种类型中的一种：TASK_FOUND，NO_TASK_FOUND或者TASK_FAILING_MEMORY_REQUIREMENT(挑选的任务内存需求得不到满足)。挑选过程的执行代码是：</p>

<pre><code>TaskLookupResult tlr = getTaskFromQueue(taskTracker, qsc);
TaskLookupResult.LookUpStatus lookUpStatus = tlr.getLookUpStatus();
</code></pre>

<p>如果以上两种都不是，则换一个队列，继续找。如果最终还没有找到，返回任务查找失败。</p>

<pre><code>printQSCs()
</code></pre>

<p>打印作业队列信息，用于调试。</p>

<pre><code>hasSpeculativeTask(TaskInProgress[] tips, TaskTrackerStatus tts)
</code></pre>

<p>检查TaskTracker是否已经被某个作业预留了。</p>

<h4>3.1.2 TaskSchedulingMgr的内部类</h4>

<p><strong>1) 内部类QueueComparator</strong></p>

<p>类QueueComparator实现了接口Comparator，对AbstractQueue对象进行排序，排序算法定义了compare()方法，比较的就是AbstractQueue对象。首先调用AbstractQueue对象中的getQueueSchedulingContext()方法，返回的类型为QueueSchedulingContext，然后调用了本地方法getTSC()，返回的是TaskSchedulingContext。</p>

<p>调用TaskSchedulingContext中的getCapacity方法，判断返回的值是否是0，若为0则值为1.0f，否则为：(double) t1.getNumSlotsOccupied() / (double) t1.getCapacity()</p>

<p><strong>2) 内部类MapQueueComparator</strong></p>

<p>该类继承类上面的类QueueComparator，只定义了一个方法，传入的类型是QueueSchedulingContext，通过调用该类中的getMapTSC()方法，返回的类型是TaskSchedulingContext。</p>

<p><strong>3) 内部类ReduceQueueComparator</strong></p>

<p>该类同样继承了QueueComparator，也只定义了一个方法，通过调用QueueSchedulingContext类中的getReduceTSC()方法，返回的类型是TaskSchedulingContext。</p>

<p><strong>4) MapSchedulingMgr/ReduceSchedulingMgr</strong></p>

<p>两个类都继承自TaskSchedulingMgr,实现了抽象方法。</p>

<p><strong>A) 类MapSchedulingMgr</strong></p>

<p>我们先讨论抽象方法在类MapSchedulingMgr中的实现。</p>

<pre><code>obtainNewTask(TaskTrackerStatus taskTracker, JobInProgress job)
</code></pre>

<p>这个函数是针对TaskTracker，从job中挑选一个task。</p>

<p>下面几个函数都是从简单的读取相应的变量，比较简单所以不讨论。</p>

<p>getClusterCapacity()读取集群的容量，即slot数</p>

<p>getTSC(QueueSchedulingContext qsi) 返回TaskSchedulingContext对象</p>

<p>hasSpeculativeTask(JobInProgress job, TaskTrackerStatus tts) 作业在taskTracker上是否有预留任务。</p>

<p><strong>B) 类ReduceSchedulingMgr</strong></p>

<p>它的实现与MapSchedulingMgr一样，代码片段如下：</p>

<pre><code>obtainNewTask(TaskTrackerStatus taskTracker, JobInProgress job)ClusterStatus clusterStatus = scheduler.taskTrackerManager.getClusterStatus();
int numTaskTrackers = clusterStatus.getTaskTrackers();
return job.obtainNewReduceTask(taskTracker, numTaskTrackers,scheduler.taskTrackerManager.getNumberOfUniqueHosts());
</code></pre>

<h3>3.2 CapacityTaskScheduler类</h3>

<p>CapacityTaskScheduler类是计算能力调度算法的主类，它主要实现了计算能力的算法，类图如图3.4。</p>

<p><img src="/images/CapacityTaskScheduler.jpg"></p>

<p>图3.4 CapacityTaskScheduler类图</p>

<h4>3.2.1 核心成员变量</h4>

<p>(1) <code>TaskSchedulingMgr mapScheduler = new MapSchedulingMgr(this)</code></p>

<p>Map任务的调度器</p>

<p>(2) <code>TaskSchedulingMgr reduceScheduler = new ReduceSchedulingMgr(this)</code></p>

<p>Reduce任务的调度器</p>

<p>(3) <code>MemoryMatcher memoryMatcher = new MemoryMatcher();</code></p>

<p>用与内存匹配</p>

<p>(4) <code>JobQueuesManager jobQueuesManager</code></p>

<p>队列管理</p>

<h4>3.2.2 CapacityTaskScheduler类实现了TaskScheduler类的方法  </h4>

<p>CapacityTaskScheduler类实现了TaskScheduler类，实现核心方法为：</p>

<p><strong> (1) start()方法</strong></p>

<p>这是MapReduce调度器的入口，在JobTracker的开始位置就是调用此方法，函数offerService()中有一句
taskScheduler.start(); taskScheduler是通过反射完成实例化</p>

<p>代码如下：</p>

<pre><code>Class&lt;? extends TaskScheduler&gt; schedulerClass=conf.getClass("mapred.jobtracker.taskScheduler",JobQueueTaskScheduler.class, TaskScheduler.class);
taskScheduler =  (TaskScheduler)ReflectionUtils.newInstance(schedulerClass, conf);
</code></pre>

<p>回到正题，start()的主要任务是：初始化配置信息，初始化队列，添加作业监听器（JobQueueManager）。start()方法的执行流程如图3.5。</p>

<p><img src="/images/start()方法流程图.jpg"></p>

<p>图3.5 start()方法的执行流程
 
 start()方法的执行步骤：</p>

<p>步骤一、初始化内存相关的信息，主要是初始化如下四个参数memSizeForMapSlotOnJT：每个map槽使用的内存大小；</p>

<ul>
<li>memSizeForReduceSlotOnJT：每个reduce槽使用的内存大小；</li>
<li>limitMaxMemForMapTasks：map任务的最大内存限制；</li>
<li>limitMaxMemForReduceTasks：reduce任务的最大内存限制。</li>
</ul>


<p>步骤二、从配置文件map-site.xml读取队列信息；</p>

<p>步骤三、从配置设置capacity-scheduler.xml初始化队列；</p>

<p>步骤四、完整性检查：确保应至少有一个队列；</p>

<p>步骤五、创建一个新的queue-hierarchy builder和尝试加载完整的层次结构的队列；</p>

<p>步骤六、创建JobQueue对象。 通知JobQueuesManager ，以便它可以跟踪running/waiting作业。 JobQueuesManager仍然是不作为监听器添加到JobTracker ，所以没有必要同步。</p>

<p>步骤七、由于创建/更改了QueueSchedulingContext对象。把它们放到队列信息中，以确保用户界面能够即时查看 。</p>

<p>步骤八、队列已经准备完成。现在注册jobQueuesManager与JobTracker ，以监听作业变动；</p>

<p>步骤九、开启初始化作业的线程，见JobInitializationPoller类的方法；</p>

<p>步骤十、start()方法执行完毕。</p>

<p><strong>(2) terminate()方法</strong></p>

<p>终止调度器，步骤如下：</p>

<p>步骤一、判断作业调度器是否启动， 如启动则执行步骤二；</p>

<p>步骤二、判断作业队列管理类是否为空，如果不为空，则清空作业队列；</p>

<p>步骤三、终止初始化作业的线程。</p>

<p>步骤四、terminate()方法执行完毕。</p>

<p><strong>(3) assignTasks(TaskTracker taskTracker)方法</strong></p>

<p>声明如下：</p>

<pre><code>public synchronized List&lt;Task&gt; assignTasks(TaskTracker taskTracker)
</code></pre>

<p>用一句话讲就是：通过一定的算法为给定的TaskTracker分配计算任务，返回结果就是计算任务集合，一般情况下是一个Map任务和一个Reduce任务。</p>

<p>那么对于CapacityScheduler来说采用的算法策略是：当某个tasktracker上出现空闲slot时，调度器依次选择一个queue、（选中的queue中的）job、（选中的job中的）task，并将该slot分配给该task，如图3.6。这些过程已经在上面的TaskScheduling及其实现类的相关方法中讨论过了。</p>

<p><img src="/images/计算能力算法策略.jpg"></p>

<p>图3.6 计算能力调度算法策略</p>

<p><strong>(4) getJobs(String queueName)</strong></p>

<p>声明：</p>

<pre><code>public synchronized Collection&lt;JobInProgress&gt; getJobs(String queueName)
</code></pre>

<p>根据队列名获取队列中的作业集合。</p>

<h4>3.2.3 CapacityTaskScheduler类实现了TaskScheduler类的内部类QueueRefresher</h4>

<p>这是一个重要的内部类，该类所实现的方法只有具有管理员权限的用户可以操作，由你们提出的作业队列的动态配置能否实现全在于该类是如何设计的，下面我们先来看看CapacityScheduler作业调度器是如何实现该内部类的。</p>

<p>CapacityScheduler作业调度器重写了该内部类的refreshQueues()方法，refreshQueues()方法的执行步骤如图3.7。</p>

<p><img src="/images/refreshQueues()方法.jpg"></p>

<p>图3.7 refreshQueues()方法的执行步骤</p>

<p>步骤一、判断作业调度器是否已经启动，如果未启动，则不能刷新队列；</p>

<p>步骤二、跟start()方法一样，它也调用了initializeQueues() 方法；</p>

<p>步骤三、判断根队列是否为空，若为空，则不能初始化根队列为空的队列；</p>

<p>步骤四、完整性检查：确保应至少有一个队列；</p>

<p>步骤五、创建一个新的queue-hierarchy builder和尝试加载完整的层次结构的队列；</p>

<p>步骤六、创建根队列newRootAbstractQueue；</p>

<p>步骤七、以newRootAbstractQueue为根队列，创建一个完整的层次结构（下面的步骤是如何创建完整的层次结构）；</p>

<p>步骤八、检查子队列是否有更多的子队列，若有则遍历子队列；若无，则执行步骤十二；</p>

<p>步骤九、检查当前被遍历到的子队列是否还有更多的子队列。若有，则生成一个新的ContainerQueue，然后递归创建层次结构；</p>

<p>步骤十、更新totalCapacity；</p>

<p>步骤十一、递归创建子层次结构；</p>

<p>步骤十二、如果这不是一个JobQueue，创建一个JobQueue（加载了配置文件中的一些有关队列的信息）；</p>

<p>步骤十三、检查每个层次的totalCapacity，对子队列的totalCapacity不应超过100 ；</p>

<p>步骤十四、向层次结构提交更改请求前，请对调度器加锁；</p>

<p>步骤十五、复制前做一些验证，如果队列的是否支持优先级改变了，则抛出异常，当前调度器还未支持是否支持优先级的改变；</p>

<p>步骤十六、首先递归更新子队列；</p>

<p>步骤十七、现在，复制根队列本身的配置；</p>

<p>步骤十八、调用JobInitializationPoller类的refreshQueueInfo()方法——刷新与初始化缓存有关的调度配置。缓存的配置，目前只能由主线程在初始化中使用。因此，主线程的迭代自动检查任何更新。</p>

<p>步骤十九、refreshQueues()方法执行完毕。</p>

<p><strong>对于步骤十五，改变当前队列是否支持优先级这一点，我们是这样理解的，队列中的作业是存储在一个Map数组中的，Map数组的比较器是可以改变的，但是改变了之后，由于Map之间是直接复制的，即使改变了该方案，Map的排列方式并未发生改变，且如果突然改变了是否支持优先级这一点。如果有新的作业提交，Map的队列会造成混乱（如果有新的成果该处会及时更新）。</strong></p>

<h3>3.3 MemoryMatcher类</h3>

<h4>3.3.1 MemoryMatcher类的成员变量</h4>

<p>类包含的主要成员变量如下：</p>

<pre><code>memSizeForMapSlotOnJT = JobConf.DISABLED_MEMORY_LIMIT;
</code></pre>

<p>对应于mapreduce.cluster.mapmemory.mb 设置的值，JobTracker上的Map槽的内存大小。</p>

<pre><code>memSizeForReduceSlotOnJT = JobConf.DISABLED_MEMORY_LIMIT;
</code></pre>

<p>对应于mapreduce.cluster.reducememory.mb设置的值，JobTracker上的Reduce槽的内存大小。</p>

<pre><code>limitMaxMemForMapTasks = JobConf.DISABLED_MEMORY_LIMIT;
</code></pre>

<p>Map任务的最大内存限制。</p>

<pre><code>limitMaxMemForReduceTasks = JobConf.DISABLED_MEMORY_LIMIT;
</code></pre>

<p>Reduce任务的最大内存限制。</p>

<h4>3.3.2 MemoryMatcher类的方法</h4>

<pre><code>getMemReservedForTasks(TaskTrackerStatus taskTracker,TaskType taskType)
</code></pre>

<p>获取给定的TaskTracker的内存使用情况。计算方法是依据TaskTracker的上报信息(TaskStatus)来计算。
matchesMemoryRequirements(JobInProgress job, TaskType taskType,TaskTrackerStatus taskTracker)
这是MemoryMatcher的核心函数，主要判断TaskTracker是否能满足指定Job的内存需求。</p>

<pre><code>isSchedulingBasedOnMemEnabled
</code></pre>

<p>调度算法是否支持内存的调度。</p>

<h3>3.4 JobInitializationPoller类</h3>

<p>关于作业的初始化，初始化的逻辑是由一个主线程和几个工作线程构成，其中，主线程周期性的从scheduler中“拖”一部分作业，把这些作业赋给工作线程，让工作线程去完成。“拖”选作业的原则是作业被调度的可能性较大，作业被调度的可能性主要：用户的作业限制，队列的容量限制。同时，高优先级的作业总是被优先初始化。</p>

<p>作业的初始化工作需要占用JobTracker的内存，因此有必要限定每个队列的初始化作业的数量。</p>

<h4>3.4.1 JobInitializationPoller类的成员变量</h4>

<p>类包含的主要成员变量如下：</p>

<ul>
<li>(1) <code>private JobQueuesManager jobQueueManager;</code>作业管理器</li>
<li>(2) <code>private long sleepInterval;</code>线程间隔时间</li>
<li>(3) <code>private int poolSize;</code>初始化规模数</li>
<li>(4) <code>private HashMap&lt;JobID, JobInProgress&gt; initializedJobs;</code>已经初始化的作业集合</li>
<li>(5) <code>private volatile boolean running;</code> 正在运行与否</li>
<li>(6) <code>private TaskTrackerManager ttm;</code></li>
<li>(7) <code>private HashMap&lt;String, JobInitializationThread&gt; threadsToQueueMap;</code>队列与为之服务的工作线程的映射关系。</li>
</ul>


<p>在讨论函数前，先把它的内部类搞定。</p>

<h4>3.4.2 内部类</h4>

<p>类JobInitializationThread</p>

<p>类JobInitializationThread的成员变量</p>

<ul>
<li>(1) <code>private JobInProgress initializingJob;</code>正在初始化的作业</li>
<li>(2) <code>private volatile boolean startIniting;</code>是否开始初始化</li>
<li>(3) <code>private AtomicInteger currentJobCount = new AtomicInteger(0);</code> 初始化作业数，它是一个原子类型。</li>
</ul>


<p>下面从执行流程来分析JobInitializationThread。</p>

<p>首先肯定是run()函数，它只调用了initializeJobs()，这个函数的主要工作是：</p>

<p>循环执行：获取每个队列的首个任务进行初始化，初始化工作由TastTrackerManager的initJob()函数完成。
这就是JobInitializationThread的核心。其它函数比较简单，在此不讨论了。</p>

<h4>3.4.3 JobInitializationPoller类的方法</h4>

<p>(1) <code>init(Set&lt;String&gt; queues, CapacitySchedulerConf capacityConf)</code></p>

<p>初始化函数，相当重要，它直接被CapacityTaskScheduler的start()函数调用，如图3.8。</p>

<p><img src="/images/JobInitializationPoller类的init()方法.jpg"></p>

<p>图3.8 初始化函数执行流程</p>

<ul>
<li>首先，确定两个变量sleepInterval（线程执行的睡眠时间），poolSize（取初始化线程数（由配置文件的”<code>mapred.capacity-scheduler.init-worker-threads</code>”决定，默认值是5）和队列大小中的较小值）的大小。</li>
<li>其次，为队列分配初始化线程（工作线程），见函数assignThreadsToQueues()。</li>
<li>最后，启动所有工作线程。</li>
</ul>


<p>(2) assignThreadsToQueues()</p>

<p>服务于每个队列的初始化线程的分配工作，由这个函数搞定。
首先创建poolSize个线程，每个线程服务${队列数/poolSize}个队列。当然，这样分配会发现有些队列没有分配线程，因此，再按照roundrobin算法（从poolSize个线程中挑选）为队列分配线程。</p>

<p>(3) run()</p>

<p>循环：</p>

<ul>
<li>1.清除已经初始化的作业列表；</li>
<li>2.选择即将初始化的作业（调用selectJobsToInitialize()），如图3.9；</li>
</ul>


<p><img src="/images/选择即将初始化的作业.jpg"></p>

<p>图3.9 选择即将初始化的作业</p>

<p>selectJobsToInitialize()，主要干活的是接下来的函数getJobsToInitialize(String)：选择作业的核心是这个函数，参数是队列名称。循环迭代队列的每一个作业：检查作业是否已经被初始化；检查队列最大初始化作业数的限制是否满足；用户限制是否满足；确认该作业还没有被kill掉。最后，将作业加入初始化队列。</p>

<h2>四、作业队列管理</h2>

<p>CapacityScheduler作业调度器定义了一个抽象的父类AbstractQueue来管理队列，同时用继承AbstractQueue的两个子类来管理队列的详细信息，最后用一个JobQueuesManager来管理所有队列。图5.1为CapacityScheduler的作业队列管理类。</p>

<p><img src="/images/CapacityScheduler作业队列管理.jpg"></p>

<p>图4.1 CapacityScheduler的作业队列管理类</p>

<h3>4.1 QueueSchedulingContext类</h3>

<p>CapacityScheduler调度器定义了一个基类来管理队列的信息QueueSchedulingContext，该基类中主要包含了如下信息</p>

<ul>
<li>queueName——队列的名称；</li>
<li>mapCapacity—— 队列的map任务在集群中的最大能力；</li>
<li>reduceCapacity——队列的reduce任务在集群中的最大能力；</li>
<li>capacityPercent——集群中在此队列中对作业有效的槽数量的百分比；</li>
<li>maxCapacityPercent——它的作用是当集群中有未在配置文件中指定能力百分比的队列时，这些队列会根据剩下的能力百分比是否能为它们分配一个百分比而设定的值；例如，在配置文件中我们为一个队列设定了能力百分比为70%，同时还有两个队列未在配置文件中指定能力百分比，则剩下的30%/未配置的队列数，此处为15%，将15%跟maxCapacityPercent比较，若它的值大于15%，则将剩下的30%的能力指定给某一个队列；</li>
<li>numJobsByUser——队列中拥有作业的用户数；</li>
<li>ulMin——用户数限制的最小值；</li>
<li>supportsPriorities ——队列是否支持优先级；</li>
<li>numOfWaitingJobs ——等待作业的数量；</li>
<li>prevMapCapacity ——MapCapacity的状态；</li>
<li>prevReduceCapacity ——ReduceCapacity的状态；</li>
<li>mapTSC——TaskSchedulingContext对象；</li>
<li>reduceTSC——TaskSchedulingContext对象。</li>
<li>TaskSchedulingContext是为了分别针对不同任务类型而设计的，它包含了如下信息：</li>
<li>capacity——实际能力，这取决于集群中还有多少槽是可用的；</li>
<li>numRunningTasks——正在运行的task数；</li>
<li>numSlotsOccupied——被占用的槽数；</li>
<li>maxCapacity——实际可扩展的能力，这取决于集群中还有多少槽是可用的；</li>
<li>numSlotsOccupiedByUser——用户占用的槽数。</li>
</ul>


<h3>4.2 AbstractQueue类</h3>

<p>AbstractQueue类是一个抽象类，它是队列层次的父类，所有队列继承这个类。</p>

<p>即使所有的队列类继承这个类，也只定义了2种类别的队列。一种是ContainerQueue类，即复合队列；另一种是JobQueue，即分级队列。通常情况下，ContainerQueue由JobQueue组成。JobQueue包括实际的作业列表，即runningJob，WaitingJob等。这样做是为了确保所有与作业相关的数据是在一个地方。</p>

<h4>4.2.1 AbstractQueue类的方法</h4>

<ul>
<li>(1) <code>update(int mapClusterCapacity, int reduceClusterCapacity)</code></li>
<li>此处其实就是调用QueueSchedulingContext类中的updateContext()方法，来更新QueueSchedulingContext类中的成员变量。</li>
<li>(2) <code>getDescendentJobQueues()</code></li>
<li>(3) <code>getDescendantContainerQueues();</code></li>
<li>(4) <code>sort(Comparator queueComparator)</code></li>
<li>(5) <code>getChildren()</code></li>
<li>(6) <code>addChild(AbstractQueue queue)</code></li>
<li>(7) <code>distributeUnConfiguredCapacity()</code></li>
<li>(2)~(7)均为抽象方法，到实现类中再讨论。</li>
<li>(8) <code>validateAndCopyQueueContexts(AbstractQueue sourceQueue)</code> 该方法主要是验证且复制队列信息。在复制前，先对队列进行验证，主要是为了提示用户新队列是否支持优先级。更新时，首先递归更新子队列。然后，复制根队列本身的配置。</li>
</ul>


<h4>4.2.2 内部类</h4>

<pre><code>AbstractQueueComparator
</code></pre>

<p>构造比较器，比较队列的名称。</p>

<h3>4.3 JobQueue类</h3>

<p>JobQueue就是维持一个队列的基本信息，包括了如下信息：</p>

<ul>
<li>comparator——队列的比较器，主要就是是否支持优先级；若不支持优先级，则根据作业的提交时间先后来对队列进行排序，如果作业的提交时间是一样的，则根据分配给作业的ID排序；</li>
<li>waitingJobs——队列中处于等待状态的作业数；</li>
<li>runningJobs——队列中处于运行状态的作业数；</li>
</ul>


<p>(1) JobQueue类的主要方法：</p>

<p>update()方法：此方法是更新当前队列</p>

<p>QueueSchedulingContext和TaskSchedulingContext中处于RUNNING状态job的信息。主要做工作的是updateStatsOnRunningJob() 方法，updateStatsOnRunningJob() 方法首先判断作业的状态是否是RUNNING状态的，如果不是，则结束该方法；若是，则继续执行。</p>

<p>更新numRunningTasks和numSlotsOccupied和numSlotsOccupiedByUser。</p>

<p>(2) getWaitingJobs()：获取正在等待的作业数。</p>

<p>Collections.unmodifiableCollection(new LinkedList<JobInProgress>(waitingJobs.values()));</p>

<p>(3) getRunningJobs()：获取处于RUNNING状态的作业列表。</p>

<ul>
<li><code>Collections.unmodifiableCollection(new LinkedList&lt;JobInProgress&gt;(runningJobs.values()))</code></li>
<li><code>addRunningJob(JobInProgress job)</code>：添加处于RUNNING状态的作业。</li>
<li><code>runningJobs.put(new JobSchedulingInfo(job), job)</code>;</li>
<li><code>removeRunningJob(JobSchedulingInfo jobInfo)</code>:移除处于RUNNING状态的作业。</li>
<li><code>runningJobs.remove(jobInfo)</code></li>
<li><code>removeWaitingJob(JobSchedulingInfo schedInfo)</code>：移除处于WAITING状态的作业。</li>
<li><code>addWaitingJob(JobInProgress job)</code>：添加处于WAITING状态的作业。</li>
<li><code>waitingJobs.put(new JobSchedulingInfo(job), job)</code>;</li>
<li><code>getWaitingJobCount()</code>：获取处于WAITING状态的作业数。</li>
<li><code>waitingJobs.size()</code>;</li>
<li><code>jobAdded(JobInProgress job)</code>：在队列中加入一个作业。它首先加入处于WAITING状态的Map函数中，然后获取该作业所属用户在队列中的作业数。如果之前没有该用户的作业，则设置该用户所属的作业数为1。然后，计算运行一个单一的map/reduce任务所需要的槽数。</li>
<li><code>jobCompleted(JobInProgress job)</code>：当一个作业完成的时候，更新相关参数，比如该作业所属于的用户在队列中占有的作业数等等。</li>
<li><code>reorderJobs(JobInProgress job, JobSchedulingInfo oldInfo)</code>：当作业的优先级或者提交时间改变时，重新排序队列。</li>
<li><code>jobUpdated(JobChangeEvent event)</code>：如果作业的状态改变了，首先如果作业的优先级或者提交时间改变了，则重新排序队列。否则如果作业的运行状态改变了，如果状态变为SUCCEEDED或者FAILED或者KILLED，执行jobCompleted(job, oldJobStateInfo);方法；否则，如果状态变为RUNNING，则执行addRunningJob(job)方法。</li>
</ul>


<h3>4.3 ContainerQueue类</h3>

<p>继承AbstractQueue，队列结构的复合类。</p>

<pre><code>private List&lt;AbstractQueue&gt; children;
</code></pre>

<p>存储子队列的数组；</p>

<p>ContainerQueue类实现父类AbstractQueue的如下方法：</p>

<pre><code>updateChildrenContext()
</code></pre>

<p>为子队列设置正常的能力值，然后更新子队列。</p>

<p>该方法遍历存储子队列的数组，为每个子队列更新计算能力信息，同时更新对象TaskSchedulingContext中的信息。</p>

<h3>4.4 队列管理类JobQueuesManager</h3>

<p>它利用一个Map函数jobQueues维护JobQueue对象，即维护一个队列。提供了如下方法：</p>

<pre><code>addQueue(JobQueue queue)
jobQueues.put(queue.getName(), queue);
</code></pre>

<p>根据队列名称，增加一个队列。</p>

<pre><code>jobAdded(JobInProgress job)
</code></pre>

<p>向某一个队列加入一个作业，它是根据作业所属队列名称而加入指定的队列。</p>

<pre><code>JobQueue qi = getJobQueue(job.getProfile().getQueueName());
qi.jobAdded(job);
jobUpdated(JobChangeEvent event)
</code></pre>

<p>根据作业的改变状态，更新作业所在的队列。</p>

<pre><code>getComparator(String queue)
</code></pre>

<p>获取队列的调度规则，即本队列是否支持优先级。</p>

<pre><code>getJobQueue(JobInProgress jip)
</code></pre>

<p>根据队列名称获取队列。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/17/linuxnei-he-yuan-ma-xiang-jie-ming-ling-pian-zhi-iostat/">Linux内核源码详解——命令篇之iostat</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-17T18:09:20+08:00" pubdate data-updated="true">May 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本文主要分析了Linux的iostat命令的源码，iostat的主要功能见博客：<a href="http://www.loveyqq.tk/blog/2014/05/09/xing-neng-ce-shi-jin-jie-zhi-nan-ji-chu-pian-zhi-ci-pan-io/">性能测试进阶指南——基础篇之磁盘IO</a></p>

<p>iostat源码共563行，应该算是Linux系统命令代码比较少的了。源代码中主要涉及到如下几个Linux的内核文件：</p>

<ul>
<li>1、<strong>/proc/diskstats</strong>——该文件是内核2.6以上的系统中的，记录了从Linux系统启动之后，所有磁盘的相关信息，该文件中每个参数代表的意义可以自行google或者baidu，或者见博客：<a href="http://blog.csdn.net/tenfyguo/article/details/7477526">/proc/diskstats参数含义</a>。</li>
<li>2、<strong>/proc/partitions</strong>——partitions是2.4版本的系统中的，其含义基本与diskstats一样。</li>
<li>3、<strong>/proc/stat</strong>——stat记录了自系统启动之后，CPU的信息，具体含义可以参考博客：性能测试进阶指南——基础篇一（系统资源的讲解）</li>
<li>4、<strong>/proc/cpuinfo</strong>——iostat主要是从该内核文件中获取cpu的核心数的。</li>
</ul>


<h3>iostat源码解析</h3>

<p><strong>第一步，从/proc/cpuinfo中获取系统的cpu核心数，通过计算该文件中processor出现的次数便可以得到cpu的核心数；</strong></p>

<p><strong>第二步，通过判断文件/proc/diskstats和/proc/partitions是否存在，从而判断linux的内核是2.4版本还是2.6版本：如果/proc/diskstats文件存在，则为2.6版本；否则判断/proc/partitions是否存在，若存在，则为2.4版本；</strong></p>

<p><strong>第三部，分析iostat命令输入的参数，每个参数的功能可以在上一篇博客中找到：</strong><a href="http://www.loveyqq.tk/blog/2014/05/09/xing-neng-ce-shi-jin-jie-zhi-nan-ji-chu-pian-zhi-ci-pan-io/">性能测试进阶指南——基础篇之磁盘IO</a></p>

<p><strong>第四步，初始化，获取磁盘名称。以内核2.6为例，读取文件/proc/diskstats</strong></p>

<pre><code>104    0 cciss/c0d0 49787 19805 1597284 159946 20172754 28596938 390157514 1583532 0 1352168 1737502  
</code></pre>

<p><strong>第一个参数104和第二个参数0分别代表了major和minor，major是8的倍数，minor是16的倍数，只要同时符合这两个的条件，其对应的第三个参数cciss/c0d0便是所需要获取的磁盘名称；</strong></p>

<p><strong>第五步，进入主循环：</strong></p>

<p><strong>(1) 获取/proc/diskstats中每个磁盘的数据</strong>，例如：</p>

<pre><code>104    0 cciss/c0d0 49787 19805 1597284 159946 20172754 28596938 390157514 1583532 0 1352168 1737502
</code></pre>

<p>每个参数对应的值为</p>

<pre><code>104——major  
0——minor  
49787——rd_ios  
19805——rd_merges  
1597284——rd_sectors  
159946——rd_ticks  
20172754——wr_ios  
28596938——wr_merges  
390157514——wr_sectors  
1583532——wr_ticks  
1352168——ticks  
1737502——aveq  
</code></pre>

<p><strong>(2) 获取/proc/stat中的数据，计算cpu的平均时间：分别获取cpu的user时间，nice时间，system时间，idle时间，iowait时间。计算中将nice时间并入user时间，将irq时间和softirq时间并入system时间。此处只计算cpu的平均和状态，不计算每隔核单独的状态。</strong></p>

<p><strong>(3)计算deltams时间，其中HZ是Linux的系统频率。</strong></p>

<pre><code>deltams = 1000.0 * ((new_cpu.user + new_cpu.system + new_cpu.idle + new_cpu.iowait) - (old_cpu.user + old_cpu.system + old_cpu.idle + old_cpu.iowait)) / ncpu / HZ; `
</code></pre>

<p><strong>(4)计算IO</strong></p>

<pre><code>blkio.rd_ios = new_blkio[p].rd_ios - old_blkio[p].rd_ios;
blkio.rd_merges = new_blkio[p].rd_merges - old_blkio[p].rd_merges;
blkio.rd_sectors = new_blkio[p].rd_sectors - old_blkio[p].rd_sectors;
blkio.rd_ticks = new_blkio[p].rd_ticks - old_blkio[p].rd_ticks;
blkio.wr_ios = new_blkio[p].wr_ios - old_blkio[p].wr_ios;
blkio.wr_merges = new_blkio[p].wr_merges - old_blkio[p].wr_merges; 
blkio.wr_sectors = new_blkio[p].wr_sectors - old_blkio[p].wr_sectors;
blkio.wr_ticks = new_blkio[p].wr_ticks - old_blkio[p].wr_ticks;
blkio.ticks = new_blkio[p].ticks - old_blkio[p].ticks;
blkio.aveq = new_blkio[p].aveq - old_blkio[p].aveq;
n_ios  = blkio.rd_ios + blkio.wr_ios;
n_ticks = blkio.rd_ticks + blkio.wr_ticks;
n_kbytes = (blkio.rd_sectors + blkio.wr_sectors) / 2.0;
queue = blkio.aveq / deltams;
size = n_ios ? n_kbytes / n_ios : 0.0;
wait = n_ios ? n_ticks / n_ios : 0.0;
svc_t = n_ios ? blkio.ticks / n_ios : 0.0;
busy = 100.0 * blkio.ticks / deltams; 
if (busy &gt; 100.0) busy = 100.0;
</code></pre>

<p><strong>rd_sectors和wr_sectors是扇区数，如果需要换算成KB等单位，需要除以2，1KB=2*512Bytes。512Bytes为1个扇区数。</strong></p>

<p><strong>(5)计算CPU</strong></p>

<pre><code>cpu.user = new_cpu.user - old_cpu.user;
cpu.system = new_cpu.system - old_cpu.system;
cpu.idle = new_cpu.idle - old_cpu.idle;
cpu.iowait = new_cpu.iowait - old_cpu.iowait;
total = (cpu.user + cpu.system + cpu.idle + cpu.iowait) / 100.0;
printf("%3.0f %3.0f ", cpu.user / total, cpu.system / total);
if (kernel == 6) printf("%3.0f ", cpu.iowait / total);
printf("%3.0f", cpu.idle / total);
</code></pre>

<p><strong>(6) Save old stats：</strong></p>

<pre><code>old_blkio[p] = new_blkio[p];
old_cpu = new_cpu;
</code></pre>

<p>每隔采样时间循环执行第五步。</p>

<p><strong>从源码中可以看出，第一次获取的时候，是没有old stats的，所有的old stats值均为0，即iostat在第一次输出的值为Linux启动之后至当前时间的一个平均状态值，在之后的输出值则为系统当前的实时磁盘I/O信息和CPU信息。</strong></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <img src="http://i.imgur.com/05V2ZMP.jpg" width="128px" height="128px">
  <p>学生生涯在<a href="http://www.nuist.edu.cn/newindex/" target="_blank">南信工</a>和<a href="http://www.upc.edu.cn/" target="_blank">石大</a>度过；</p>
  <p>现在就职于<a href="http://www.fengqu.com/" target="_blank">丰趣海淘（顺丰旗下跨境电商）</a>；</p> 
  <p>本站所有内容均属个人观点，和本人雇主及其他团体无关。</p>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/03/26/zeng-chang-hei-ke-ying-dang-guan-zhu-de-chang-yong-zhi-biao/">增长黑客应当关注的常用指标</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/24/sparkkai-fa-huan-jing-da-jian/">Spark开发环境搭建</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/23/sparkji-suan-mo-xing/">Spark计算模型</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/02/sparkjian-jie-yu-ji-suan-mo-xing/">Spark简介</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/01/25/sparkzhong-yong-sparksqlcao-zuo-hive/">spark中用SparkSql操作Hive</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>我在看(听)的</h1>
  <div>
     <script type="text/javascript" src="http://www.douban.com/service/badge/ggchange/?selection=latest&amp;picsize=small&amp;hideself=on&amp;show=dolist&amp;n=3&amp;hidelogo=on&amp;cat=drama%7Cmovie%7Cbook%7Cmusic&amp;columns=3"></script>
  </div>
</section><section>
	<h1>Visitors: </h1>
	<script type="text/javascript" src="http://jf.revolvermaps.com/2/4.js?i=5m0y5r013zc&amp;m=0&amp;h=128&amp;c=54ff00&amp;r=40" async="async"></script>
</section>
<section>
<h1>常用站点</h1>
<ul>
        <li>
        <a href="http://blog.csdn.net/gao715108023/">CSDN博客</a>
        </li>
        <li>
        <a href="http://www.zhihu.com/">知乎</a>
        </li>
        <li>
        <a href="http://zh.lucida.me/">Lucida</a>
        </li>
        <li>
        <a href="http://vivaxy.tk/">vivaxy</a>
        </li>
</ul>
</section>
<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/gao715108023">@gao715108023</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'gao715108023',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - GaoChuanjun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
